# =============================================================================
#
# Author:   Kjell Swedin
# Purpose: Drive regression test
#
# =============================================================================
import os
import sys
import pandas as pd
import glob
import numpy as np

CALCULATED_VALUES = 'calculated_values.csv'
EXPECTED_VALUES = 'expected.csv'
SCRATCH_FILENAME = 'zorK123.csv'
OUTDIR = './out'

OPTIONAL_LOADING = {
    'eGROUND_FUEL_BASAL_ACCUMULATION_LOADING',
    'eGROUND_FUEL_DUFF_LOWER_LOADING',
    'eGROUND_FUEL_DUFF_UPPER_LOADING',
    'eGROUND_FUEL_SQUIRREL_MIDDENS_LOADING',
    'eMOSS_LICHEN_LITTER_GROUND_LICHEN_LOADING',
    'eMOSS_LICHEN_LITTER_LITTER_LOADING',
    'eMOSS_LICHEN_LITTER_MOSS_LOADING',
    'eSHRUBS_PRIMARY_LAYER_LOADING',
    'eSHRUBS_SECONDARY_LAYER_LOADING'
    }

# =============================================================================
#   Remove all the artifacts generated by running this script -- "make clean"
# =============================================================================
CLEAN = 'clean'
def clean():
    def on_error():
        print('some sort of error...')
    
    for i in [CALCULATED_VALUES, EXPECTED_VALUES, SCRATCH_FILENAME]:
        try:
            os.remove(i)
        except: pass
    for i in [OUTDIR]:
        try:
            cmd = 'rm -fr {}'.format(OUTDIR)
            os.system(cmd)
        except: pass
        
def is_clean(argv):
    yes_clean = False
    for j in [i.lower() for i in argv]:
        if CLEAN in j:
            yes_clean = True
            break
    return yes_clean

def calculate_values():
    cmd = 'python3 ../run_disturbance/scripts/main.py regression_fuelbeds/*.xml'
    os.system(cmd)

def collect_calculated_values():
    def get_values(filename):
        cmd = 'python3 print_values_from_xml.py {}> {}'.format(filename, SCRATCH_FILENAME)
        os.system(cmd)
        df = pd.read_csv(SCRATCH_FILENAME, header=None, names=['Variable', 'Value'])
        df.fillna(0, inplace=True)
        os.unlink(SCRATCH_FILENAME)
        return df

    def get_values_from_files():
        first_time = True
        df_out = None
        files = glob.glob('{}/*.xml'.format(OUTDIR))
        for f in files:
            print(f)
            df = get_values(f)
            colname = f[len(OUTDIR)+1:].split('.')[0]
            if not first_time:
                df_out[colname] = df.Value
            else:
                df_out = pd.DataFrame({'Variable': df.Variable, colname: df.Value})
                first_time = False
        df_out.to_csv(CALCULATED_VALUES, index=False)
    get_values_from_files()
    
def build_expected_value_csv():
    files = glob.glob('../specifications/*.xlsx')
    df_result = pd.read_excel(files[0], sheetname='Expected')
    df_result.drop([i for i in df_result.columns if i.endswith('FCCS')], axis=1, inplace=True)
    for f in files[1:]:
        df = pd.read_excel(f, sheetname='Expected')
        df.drop([i for i in df.columns if i.endswith('FCCS')], axis=1, inplace=True)
        df_result = pd.merge(df_result, df, on='Variable')
    df_result.to_csv(EXPECTED_VALUES, index=False)
    
def compare_outputs():
    def compare_item(zip_item):
        # item looks like: ((14, 60.0), (14, '60'))
        retval = False
        try:
            calculated = float(zip_item[1][1])
            retval = np.isclose(zip_item[0][1], calculated, rtol=1e-02)
        except:
            pass
        return retval
        
    print('\n\nComparing outputs...')    
    df_expected = pd.read_csv(EXPECTED_VALUES)
    df_calculated = pd.read_csv(CALCULATED_VALUES)
    compare_these = set(df_expected.columns).intersection(set(df_calculated.columns))
    skip_these = set(df_calculated.columns).difference(set(df_expected.columns))
    
    # drop columns that expected doesn't have
    df_calculated.drop(skip_these, axis=1, inplace=True)
    
    # remove rows that expected doesn't have
    df_calculated = df_calculated[df_calculated.Variable.isin(df_expected.Variable)]
    
    # check - remove this if the optional loading rows are removed from the specifications
    assert set() == set(df_expected.Variable).difference(set(df_calculated.Variable))
    
    # remove optional loading columns
    df_expected = df_expected[df_expected.Variable.isin(df_calculated.Variable)]
    
    # order identically
    df_expected = df_expected.sort_values('Variable').reset_index(drop=True)
    df_calculated = df_calculated.sort_values('Variable').reset_index(drop=True)
    
    columns = list(df_expected.columns)
    columns.remove('Variable')
    compare_count = 0
    compare_successful = 0
    compare_failed = 0
    files_skipped = []
    for column in columns:
        print(' --- ', column)
        if column in df_calculated.columns:
            for i in zip(df_expected.get(column).iteritems(), df_calculated.get(column).iteritems()):
                if not compare_item(i):
                    compare_failed += 1
                    print('\tFAILURE: {} expected\t: {} calculated ({})'.format(
                            np.round(float(i[0][1]), 3),
                            np.round(float(i[1][1]), 3),
                            df_expected.Variable[i[0][0]]))
                else:
                    compare_successful += 1
                compare_count += 1
        else:
            files_skipped.append(column)
    
    if len(files_skipped):
        print('\nThe following files did not have calculated values. Were they skipped?')
        for i in files_skipped:
            print('\t{}'.format(i))
    print('\n{} Comparisons\n\t{} Successful\n\t{} Unsuccessful'.format(compare_count, compare_successful, compare_failed))
    return compare_failed
    
    
# ++++++++++++++++++++++++++++++++++++++++++
#  Start...
# ++++++++++++++++++++++++++++++++++++++++++
clean()
if len(sys.argv) > 1 and is_clean(sys.argv):
    exit(0)
else:
    calculate_values()
    collect_calculated_values()
    build_expected_value_csv()
    result = compare_outputs()
    exit(result)
